{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5deb51c070bf",
   "metadata": {},
   "source": [
    "# Workbook 03   Multi-Architecture Model Development\n",
    "\n",
    "**Objective:** Systematic comparison of GNN architectures for subgraph-level AML\n",
    "classification on Elliptic2, with Optuna-driven hyperparameter optimisation and\n",
    "reproducible evaluation.\n",
    "\n",
    "**Builds on:**\n",
    "- Workbook 01: preprocessing pipeline, node features, stratified splits\n",
    "- Workbook 02: dataset interface, LogReg + default GraphSAGE baselines\n",
    "\n",
    "**Deliverables:**\n",
    "- Tuned GraphSAGE, GCN, and GATv2 models with optimal hyperparameters\n",
    "- Cross-architecture performance comparison (PR-AUC, ROC-AUC, F1)\n",
    "- Cross-study comparison against Bellei et al. (2024) results\n",
    "- Training curves, PR/ROC curves, confusion matrices\n",
    "- Best model checkpoint for downstream explainability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b0199330c",
   "metadata": {},
   "source": [
    "## 0. Configuration and reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f0961af32c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpruners\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MedianPruner\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msamplers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TPESampler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GATv2Conv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 7\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RNG_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR     = PROJECT_ROOT / \"DATA\"\n",
    "PROCESSED    = DATA_DIR / \"processed\"\n",
    "ARRAYS_DIR   = PROCESSED / \"arrays\"\n",
    "ARTIFACTS_DIR = PROCESSED / \"artifacts\"\n",
    "PACK_DIR     = ARTIFACTS_DIR / \"packed\"\n",
    "RESULTS_DIR  = PROJECT_ROOT / \"results\"\n",
    "WB03_DIR     = RESULTS_DIR / \"wb03\"\n",
    "\n",
    "WB03_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89fd004883",
   "metadata": {},
   "source": [
    "## 1. Load preprocessed artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44745b200a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column schema (matches Wb01/Wb02)\n",
    "NODE_ID_COL    = \"clId\"\n",
    "NODES_COMP_COL = \"ccId\"\n",
    "CC_LABEL_COL   = \"ccLabel\"\n",
    "\n",
    "#   Core data                         \n",
    "nodes = pd.read_parquet(PROCESSED / \"parquet\" / \"nodes.parquet\")\n",
    "X     = np.load(ARRAYS_DIR / \"node_features.npy\")\n",
    "\n",
    "subgraph_labels = {\n",
    "    int(k): v\n",
    "    for k, v in json.loads((ARTIFACTS_DIR / \"subgraph_labels.json\").read_text()).items()\n",
    "}\n",
    "splits = json.loads((ARTIFACTS_DIR / \"splits.json\").read_text())\n",
    "\n",
    "#   Packing arrays (from Wb02)                ─\n",
    "nodes_pack    = np.load(PACK_DIR / \"nodes_by_ccid.npz\")\n",
    "edges_pack    = np.load(PACK_DIR / \"edges_by_ccid.npz\")\n",
    "\n",
    "unique_cc       = nodes_pack[\"unique_cc\"].astype(np.int64)\n",
    "node_ptr        = nodes_pack[\"node_ptr\"].astype(np.int64)\n",
    "node_row_perm   = nodes_pack[\"node_row_perm\"].astype(np.int64)\n",
    "\n",
    "unique_cc_edges   = edges_pack[\"unique_cc_edges\"].astype(np.int64)\n",
    "edge_ptr          = edges_pack[\"edge_ptr\"].astype(np.int64)\n",
    "edge_src_row_perm = edges_pack[\"edge_src_row_perm\"].astype(np.int64)\n",
    "edge_dst_row_perm = edges_pack[\"edge_dst_row_perm\"].astype(np.int64)\n",
    "\n",
    "ccid_to_i  = {int(c): i for i, c in enumerate(unique_cc)}\n",
    "ccid_to_ei = {int(c): i for i, c in enumerate(unique_cc_edges)}\n",
    "\n",
    "def label_to_int(lbl: str) -> int:\n",
    "    return 1 if str(lbl).lower() in {\"suspicious\", \"illicit\"} else 0\n",
    "\n",
    "y_by_cc = {int(c): label_to_int(subgraph_labels[int(c)]) for c in unique_cc}\n",
    "\n",
    "print(f\"Nodes: {X.shape[0]:,}  Features: {X.shape[1]}\")\n",
    "print(f\"Subgraphs: {len(unique_cc):,}  Suspicious: {sum(y_by_cc.values()):,}\"\n",
    "      f\" ({100*sum(y_by_cc.values())/len(unique_cc):.2f}%)\")\n",
    "print(f\"Splits   train: {len(splits['train']):,}  val: {len(splits['val']):,}\"\n",
    "      f\"  test: {len(splits['test']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7dde600286",
   "metadata": {},
   "source": [
    "## 2. Dataset and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f767e20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elliptic2SubgraphDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Lazy PyG dataset: one Data object per subgraph (ccId).\n",
    "\n",
    "    Each Data object contains:\n",
    "        x:          [n_nodes, 43] float tensor   node features\n",
    "        edge_index: [2, n_edges]  long tensor    undirected edges\n",
    "        y:          [1]           long tensor     subgraph label\n",
    "        ccId:       int                           component identifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ccids: np.ndarray, make_undirected: bool = True):\n",
    "        self.ccids = ccids.astype(np.int64)\n",
    "        self.make_undirected = make_undirected\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.ccids.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Data:\n",
    "        ccid = int(self.ccids[idx])\n",
    "        i = ccid_to_i[ccid]\n",
    "        rows = node_row_perm[node_ptr[i] : node_ptr[i + 1]]\n",
    "        x = torch.from_numpy(X[rows]).float()\n",
    "\n",
    "        local = {int(r): j for j, r in enumerate(rows.tolist())}\n",
    "\n",
    "        if ccid in ccid_to_ei:\n",
    "            ei = ccid_to_ei[ccid]\n",
    "            s = edge_src_row_perm[edge_ptr[ei] : edge_ptr[ei + 1]]\n",
    "            t = edge_dst_row_perm[edge_ptr[ei] : edge_ptr[ei + 1]]\n",
    "            src = torch.tensor([local[int(r)] for r in s], dtype=torch.long)\n",
    "            dst = torch.tensor([local[int(r)] for r in t], dtype=torch.long)\n",
    "            edge_index = torch.stack([src, dst], dim=0)\n",
    "            if self.make_undirected:\n",
    "                edge_index = to_undirected(edge_index)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        y = torch.tensor([y_by_cc[ccid]], dtype=torch.long)\n",
    "        return Data(x=x, edge_index=edge_index, y=y, ccId=ccid)\n",
    "\n",
    "\n",
    "#   Instantiate splits                    ─\n",
    "train_cc = np.array(splits[\"train\"], dtype=np.int64)\n",
    "val_cc   = np.array(splits[\"val\"],   dtype=np.int64)\n",
    "test_cc  = np.array(splits[\"test\"],  dtype=np.int64)\n",
    "\n",
    "train_ds = Elliptic2SubgraphDataset(train_cc)\n",
    "val_ds   = Elliptic2SubgraphDataset(val_cc)\n",
    "test_ds  = Elliptic2SubgraphDataset(test_cc)\n",
    "\n",
    "#   Class weights (inverse frequency, computed on train only) ─\n",
    "train_labels = torch.tensor([y_by_cc[int(c)] for c in train_cc], dtype=torch.long)\n",
    "n_pos = int(train_labels.sum().item())\n",
    "n_neg = int((train_labels == 0).sum().item())\n",
    "CLASS_WEIGHTS = torch.tensor([1.0, n_neg / max(n_pos, 1)], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "IN_DIM = X.shape[1]  # 43\n",
    "\n",
    "print(f\"Class weights: licit={CLASS_WEIGHTS[0]:.1f}, suspicious={CLASS_WEIGHTS[1]:.1f}\")\n",
    "print(f\"Input feature dimension: {IN_DIM}\")\n",
    "print(f\"Sample Data object: {train_ds[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c244c5e508",
   "metadata": {},
   "source": [
    "## 3. Model architectures\n",
    "\n",
    "Three GNN backbones, unified by a common interface:\n",
    "\n",
    "| Architecture | Aggregation | Key property |\n",
    "|:--|:--|:--|\n",
    "| **GraphSAGE** | Learned mean/max with self/neighbour separation | Inductive, scalable |\n",
    "| **GCN** | Degree-normalised symmetric sum | Spectral grounding, XAI baseline |\n",
    "| **GATv2** | Dynamic learned attention weights | Intrinsic interpretability |\n",
    "\n",
    "All models follow the same pattern:\n",
    "`GNN layers → global pooling → MLP classification head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fa9adf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "POOL_FN = {\"mean\": global_mean_pool, \"max\": global_max_pool}\n",
    "\n",
    "\n",
    "class SubgraphClassifier(nn.Module):\n",
    "    \"\"\"Unified GNN subgraph classifier.\n",
    "\n",
    "    Architecture:\n",
    "        [GNN backbone]  node-level message passing (n layers)\n",
    "        [Global pool]   aggregate node embeddings per subgraph\n",
    "        [MLP head]      two-layer classifier → 2-class logits\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arch : str\n",
    "        One of 'sage', 'gcn', 'gatv2'.\n",
    "    in_dim : int\n",
    "        Input feature dimension (43 for Elliptic2).\n",
    "    hidden_dim : int\n",
    "        Hidden dimension for GNN layers and MLP.\n",
    "    num_layers : int\n",
    "        Number of GNN message-passing layers.\n",
    "    dropout : float\n",
    "        Dropout probability applied after each GNN layer.\n",
    "    pool : str\n",
    "        Global pooling strategy: 'mean' or 'max'.\n",
    "    heads : int\n",
    "        Number of attention heads (GATv2 only; ignored for others).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: str,\n",
    "        in_dim: int,\n",
    "        hidden_dim: int = 64,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.0,\n",
    "        pool: str = \"mean\",\n",
    "        heads: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.dropout = dropout\n",
    "        self.pool_fn = POOL_FN[pool]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            c_in = in_dim if i == 0 else hidden_dim\n",
    "\n",
    "            if arch == \"sage\":\n",
    "                self.convs.append(SAGEConv(c_in, hidden_dim))\n",
    "            elif arch == \"gcn\":\n",
    "                self.convs.append(GCNConv(c_in, hidden_dim))\n",
    "            elif arch == \"gatv2\":\n",
    "                if i < num_layers - 1:\n",
    "                    # Intermediate: multi-head, concat → output = (hidden//heads)*heads\n",
    "                    per_head = max(hidden_dim // heads, 1)\n",
    "                    self.convs.append(GATv2Conv(c_in, per_head, heads=heads, concat=True))\n",
    "                    # Override c_in for next layer\n",
    "                    in_dim = per_head * heads\n",
    "                    hidden_dim_actual = per_head * heads\n",
    "                else:\n",
    "                    # Final: single head → output = hidden_dim\n",
    "                    self.convs.append(GATv2Conv(c_in, hidden_dim, heads=1, concat=False))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown architecture: {arch}\")\n",
    "\n",
    "            # BatchNorm over actual output dim\n",
    "            if arch == \"gatv2\" and i < num_layers - 1:\n",
    "                self.bns.append(nn.BatchNorm1d(per_head * heads))\n",
    "            else:\n",
    "                self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        #   MLP classification head  \n",
    "        self.lin1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = conv(x, edge_index)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            if self.dropout > 0:\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        g = self.pool_fn(x, batch)\n",
    "        g = F.relu(self.lin1(g))\n",
    "        if self.dropout > 0:\n",
    "            g = F.dropout(g, p=self.dropout, training=self.training)\n",
    "        return self.lin2(g)\n",
    "\n",
    "\n",
    "#   Smoke test                        ─\n",
    "for arch in [\"sage\", \"gcn\", \"gatv2\"]:\n",
    "    m = SubgraphClassifier(arch=arch, in_dim=IN_DIM, hidden_dim=64, heads=2)\n",
    "    n_params = sum(p.numel() for p in m.parameters())\n",
    "    print(f\"{arch:6s} | params: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88772511a0",
   "metadata": {},
   "source": [
    "## 4. Training infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661526ecf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, loader: PyGDataLoader) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Run inference; return (y_true, y_score) arrays.\"\"\"\n",
    "    model.eval()\n",
    "    ys, scores = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(DEVICE)\n",
    "            logits = model(batch)\n",
    "            prob = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "            y = batch.y.cpu().numpy().reshape(-1)\n",
    "            ys.append(y)\n",
    "            scores.append(prob)\n",
    "    return np.concatenate(ys), np.concatenate(scores)\n",
    "\n",
    "\n",
    "def optimal_threshold(y_true: np.ndarray, y_score: np.ndarray) -> float:\n",
    "    \"\"\"Find the threshold that maximises F1 on a given split.\"\"\"\n",
    "    prec, rec, thresholds = precision_recall_curve(y_true, y_score)\n",
    "    f1 = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "    best_idx = int(np.nanargmax(f1))\n",
    "    return float(thresholds[max(best_idx - 1, 0)]) if len(thresholds) else 0.5\n",
    "\n",
    "\n",
    "def compute_test_metrics(y_true: np.ndarray, y_score: np.ndarray, threshold: float) -> dict:\n",
    "    \"\"\"Compute all test-set metrics at a given decision threshold.\"\"\"\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return {\n",
    "        \"test_pr_auc\":     float(average_precision_score(y_true, y_score)),\n",
    "        \"test_roc_auc\":    float(roc_auc_score(y_true, y_score)),\n",
    "        \"test_f1\":         float(f1_score(y_true, y_pred)),\n",
    "        \"test_precision\":  float(tp / max(tp + fp, 1)),\n",
    "        \"test_recall\":     float(tp / max(tp + fn, 1)),\n",
    "        \"test_threshold\":  float(threshold),\n",
    "        \"test_confusion\":  cm.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddb85d5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    arch: str,\n",
    "    hidden_dim: int,\n",
    "    num_layers: int,\n",
    "    dropout: float,\n",
    "    lr: float,\n",
    "    pool: str,\n",
    "    heads: int = 2,\n",
    "    batch_size: int = 256,\n",
    "    max_epochs: int = 80,\n",
    "    patience: int = 15,\n",
    "    trial: optuna.Trial | None = None,\n",
    "    verbose: bool = False,\n",
    "    trial_num: int | None = None,\n",
    "    show_epoch_progress: bool = False,\n",
    "    epoch_progress_every: int = 1,\n",
    ") -> dict:\n",
    "    \"\"\"Train a single model configuration end-to-end.\n",
    "\n",
    "    If an Optuna trial is provided, reports intermediate values for pruning.\n",
    "\n",
    "    Returns a dict with all metrics, training history, and hyperparameters.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_loader = PyGDataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = PyGDataLoader(val_ds, batch_size=512, shuffle=False)\n",
    "    test_loader = PyGDataLoader(test_ds, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = SubgraphClassifier(\n",
    "        arch=arch, in_dim=IN_DIM, hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers, dropout=dropout, pool=pool, heads=heads,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    best_val_pr = -1.0\n",
    "    best_state = None\n",
    "    best_epoch = 0\n",
    "    bad_epochs = 0\n",
    "    train_losses, val_pr_aucs, val_roc_aucs = [], [], []\n",
    "\n",
    "    epoch_progress_every = max(1, int(epoch_progress_every))\n",
    "    epoch_iter = range(1, max_epochs + 1)\n",
    "    epoch_pbar = None\n",
    "\n",
    "    if show_epoch_progress:\n",
    "        trial_label = f\"{arch.upper()} trial {trial_num}\" if trial_num is not None else f\"{arch.upper()} trial\"\n",
    "        epoch_pbar = tqdm(\n",
    "            epoch_iter,\n",
    "            total=max_epochs,\n",
    "            desc=trial_label,\n",
    "            leave=False,\n",
    "            dynamic_ncols=True,\n",
    "            position=1,\n",
    "        )\n",
    "        epoch_iter = epoch_pbar\n",
    "\n",
    "    try:\n",
    "        for epoch in epoch_iter:\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(batch)\n",
    "                loss = criterion(logits, batch.y.view(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "            avg_loss = epoch_loss / len(train_ds)\n",
    "            train_losses.append(avg_loss)\n",
    "\n",
    "            yv, sv = evaluate(model, val_loader)\n",
    "            vp = float(average_precision_score(yv, sv))\n",
    "            vr = float(roc_auc_score(yv, sv))\n",
    "            val_pr_aucs.append(vp)\n",
    "            val_roc_aucs.append(vr)\n",
    "\n",
    "            if epoch_pbar is not None and (\n",
    "                epoch % epoch_progress_every == 0 or epoch == 1 or epoch == max_epochs\n",
    "            ):\n",
    "                epoch_pbar.set_postfix_str(\n",
    "                    f\"epoch {epoch}/{max_epochs} val_pr={vp:.4f}\",\n",
    "                    refresh=False,\n",
    "                )\n",
    "\n",
    "            if verbose and epoch % 10 == 0:\n",
    "                print(f\"    epoch {epoch:3d}  loss={avg_loss:.4f}\"\n",
    "                      f\"  val_pr={vp:.4f}  val_roc={vr:.4f}\")\n",
    "\n",
    "            if trial is not None:\n",
    "                trial.report(vp, epoch)\n",
    "                if trial.should_prune():\n",
    "                    if epoch_pbar is not None:\n",
    "                        epoch_pbar.set_postfix_str(\n",
    "                            f\"epoch {epoch}/{max_epochs} pruned\",\n",
    "                            refresh=True,\n",
    "                        )\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            if vp > best_val_pr + 1e-4:\n",
    "                best_val_pr = vp\n",
    "                best_state = {k: v.detach().cpu().clone()\n",
    "                              for k, v in model.state_dict().items()}\n",
    "                best_epoch = epoch\n",
    "                bad_epochs = 0\n",
    "            else:\n",
    "                bad_epochs += 1\n",
    "                if bad_epochs >= patience:\n",
    "                    if epoch_pbar is not None:\n",
    "                        epoch_pbar.set_postfix_str(\n",
    "                            f\"epoch {epoch}/{max_epochs} early-stop\",\n",
    "                            refresh=True,\n",
    "                        )\n",
    "                    if verbose:\n",
    "                        print(f\"    early stop at epoch {epoch} (best={best_epoch})\")\n",
    "                    break\n",
    "    finally:\n",
    "        if epoch_pbar is not None:\n",
    "            epoch_pbar.close()\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    yv, sv = evaluate(model, val_loader)\n",
    "    best_thr = optimal_threshold(yv, sv)\n",
    "    yt, st = evaluate(model, test_loader)\n",
    "    test_m = compute_test_metrics(yt, st, best_thr)\n",
    "\n",
    "    wall = time.time() - t0\n",
    "\n",
    "    head_str = f\"_h{heads}\" if arch == \"gatv2\" else \"\"\n",
    "    label = (f\"{arch}_hid{hidden_dim}_L{num_layers}\"\n",
    "             f\"_drop{dropout}_lr{lr}_{pool}{head_str}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        torch.save(best_state, WB03_DIR / f\"{label}_state.pt\")\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"arch\": arch,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"dropout\": dropout,\n",
    "        \"lr\": lr,\n",
    "        \"pool\": pool,\n",
    "        \"heads\": heads,\n",
    "        \"n_params\": n_params,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_val_pr_auc\": best_val_pr,\n",
    "        \"best_val_roc_auc\": max(val_roc_aucs) if val_roc_aucs else 0.0,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_pr_aucs\": val_pr_aucs,\n",
    "        \"val_roc_aucs\": val_roc_aucs,\n",
    "        \"wall_seconds\": wall,\n",
    "        **test_m,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d14dfc03e",
   "metadata": {},
   "source": [
    "## 5. Optuna hyperparameter optimisation\n",
    "\n",
    "**Strategy:** Per-architecture Bayesian search using Optuna's TPE sampler, with\n",
    "median pruning to kill unpromising trials early.\n",
    "\n",
    "| Parameter | Range | Type |\n",
    "|:--|:--|:--|\n",
    "| `hidden_dim` | {64, 128, 256} | Categorical |\n",
    "| `num_layers` | {2, 3} | Categorical |\n",
    "| `dropout` | 0.0 – 0.5 | Continuous |\n",
    "| `lr` | 1e-4 – 5e-3 | Log-uniform |\n",
    "| `pool` | {mean, max} | Categorical |\n",
    "| `heads` | {1, 2, 4} | Categorical (GATv2 only) |\n",
    "\n",
    "**Why Optuna over grid search?**\n",
    "- **TPE sampler** learns which regions of the space are promising and\n",
    "  samples more trials there, requiring fewer total evaluations.\n",
    "- **Median pruner** stops a trial at epoch *e* if its validation PR-AUC\n",
    "  is below the median of completed trials at that epoch, saving\n",
    "  significant GPU time on poor configurations.\n",
    "- **Continuous ranges** for dropout and learning rate (vs the 2-value\n",
    "  grid before) explore the space more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc639558989",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS_PER_ARCH = 30  # ← adjust for your GPU budget\n",
    "\n",
    "def make_objective(arch: str):\n",
    "    \"\"\"Create an Optuna objective function for a given architecture.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "        num_layers = trial.suggest_categorical(\"num_layers\", [2, 3])\n",
    "        dropout    = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.05)\n",
    "        lr         = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        pool       = trial.suggest_categorical(\"pool\", [\"mean\", \"max\"])\n",
    "\n",
    "        heads = 2\n",
    "        if arch == \"gatv2\":\n",
    "            heads = trial.suggest_categorical(\"heads\", [1, 2, 4])\n",
    "\n",
    "        result = train_and_evaluate(\n",
    "            arch=arch,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            lr=lr,\n",
    "            pool=pool,\n",
    "            heads=heads,\n",
    "            trial=trial,\n",
    "            trial_num=trial.number,\n",
    "            show_epoch_progress=True,\n",
    "            epoch_progress_every=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Store full result dict on the trial for later retrieval\n",
    "        trial.set_user_attr(\"result\", result)\n",
    "        return result[\"best_val_pr_auc\"]\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a313049d8f",
   "metadata": {},
   "source": [
    "### Execute optimisation\n",
    "\n",
    "**Note:** Each architecture runs `N_TRIALS_PER_ARCH` trials. On a modern GPU this takes 1–4 hours total. Optuna's pruner will cut ~30–50% of trials short, saving significant time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863de4013146",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = {}\n",
    "all_results = []\n",
    "\n",
    "for arch in [\"sage\", \"gcn\", \"gatv2\"]:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" Optimising {arch.upper()}   {N_TRIALS_PER_ARCH} trials\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=f\"wb03_{arch}\",\n",
    "        direction=\"maximize\",\n",
    "        sampler=TPESampler(seed=RNG_SEED),\n",
    "        pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=10),\n",
    "    )\n",
    "    study.optimize(make_objective(arch), n_trials=N_TRIALS_PER_ARCH, show_progress_bar=True)\n",
    "\n",
    "    studies[arch] = study\n",
    "\n",
    "    # Collect results from completed (non-pruned) trials\n",
    "    for trial in study.trials:\n",
    "        if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "            all_results.append(trial.user_attrs[\"result\"])\n",
    "\n",
    "    # Summary\n",
    "    best = study.best_trial\n",
    "    print(f\"\\n  Best trial #{best.number}:\")\n",
    "    print(f\"    val PR-AUC = {best.value:.4f}\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"    {k} = {v}\")\n",
    "\n",
    "    n_pruned = sum(1 for t in study.trials if t.state == optuna.trial.TrialState.PRUNED)\n",
    "    print(f\"  Pruned: {n_pruned}/{N_TRIALS_PER_ARCH}\"\n",
    "          f\" ({100*n_pruned/N_TRIALS_PER_ARCH:.0f}%   GPU time saved)\")\n",
    "\n",
    "#   Persist all results                    \n",
    "RESULTS_PATH = WB03_DIR / \"search_results.json\"\n",
    "RESULTS_PATH.write_text(json.dumps(all_results, indent=2))\n",
    "print(f\"\\nSaved {len(all_results)} completed trial results to {RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9a7e6b3c0",
   "metadata": {},
   "source": [
    "### Optuna study diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a192555681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "for col, (arch, display) in enumerate([(\"sage\", \"GraphSAGE\"),\n",
    "                                        (\"gcn\", \"GCN\"),\n",
    "                                        (\"gatv2\", \"GATv2\")]):\n",
    "    study = studies[arch]\n",
    "\n",
    "    # Row 0: optimisation history\n",
    "    ax = axes[0, col]\n",
    "    vals = [t.value for t in study.trials if t.value is not None]\n",
    "    ax.plot(vals, \"o-\", markersize=4, alpha=0.7)\n",
    "    ax.axhline(study.best_value, color=\"red\", ls=\"--\", alpha=0.5, label=f\"Best: {study.best_value:.4f}\")\n",
    "    ax.set_title(f\"{display}   optimisation history\")\n",
    "    ax.set_xlabel(\"Trial\")\n",
    "    ax.set_ylabel(\"Val PR-AUC\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Row 1: parameter importances\n",
    "    ax = axes[1, col]\n",
    "    try:\n",
    "        importances = optuna.importance.get_param_importances(study)\n",
    "        params = list(importances.keys())\n",
    "        values = list(importances.values())\n",
    "        ax.barh(params, values, color=\"#2196F3\", alpha=0.8)\n",
    "        ax.set_title(f\"{display}   parameter importance\")\n",
    "        ax.set_xlabel(\"Importance (fANOVA)\")\n",
    "    except Exception:\n",
    "        ax.text(0.5, 0.5, \"Not enough trials\\nfor importance\", ha=\"center\", va=\"center\")\n",
    "        ax.set_title(f\"{display}   parameter importance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(WB03_DIR / \"optuna_diagnostics.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: optuna_diagnostics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8738eb0a33",
   "metadata": {},
   "source": [
    "## 6. Results compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43786f5dc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Load all results                     ─\n",
    "results_raw = json.loads(RESULTS_PATH.read_text())\n",
    "df = pd.DataFrame(results_raw)\n",
    "\n",
    "#   Best model per architecture                \n",
    "print(\"=\" * 80)\n",
    "print(\"BEST MODEL PER ARCHITECTURE (by validation PR-AUC)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_models = {}\n",
    "for arch in [\"sage\", \"gcn\", \"gatv2\"]:\n",
    "    arch_df = df[df[\"arch\"] == arch].copy()\n",
    "    best_idx = arch_df[\"best_val_pr_auc\"].idxmax()\n",
    "    best = arch_df.loc[best_idx]\n",
    "    best_models[arch] = best\n",
    "    print(f\"\\n  {arch.upper()}  \")\n",
    "    print(f\"  Config:   hidden={int(best['hidden_dim'])}, layers={int(best['num_layers'])},\"\n",
    "          f\" dropout={best['dropout']:.2f}, lr={best['lr']:.5f}, pool={best['pool']}\"\n",
    "          + (f\", heads={int(best['heads'])}\" if arch == \"gatv2\" else \"\"))\n",
    "    print(f\"  Val  PR-AUC: {best['best_val_pr_auc']:.4f}\")\n",
    "    print(f\"  Test PR-AUC: {best['test_pr_auc']:.4f}   ROC-AUC: {best['test_roc_auc']:.4f}\")\n",
    "    print(f\"  Test F1:     {best['test_f1']:.4f}   Prec: {best['test_precision']:.4f}\"\n",
    "          f\"  Rec: {best['test_recall']:.4f}\")\n",
    "    print(f\"  Params: {int(best['n_params']):,}   Best epoch: {int(best['best_epoch'])}\"\n",
    "          f\"   Wall: {best['wall_seconds']:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e6881223f",
   "metadata": {},
   "source": [
    "### Model comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a98757807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Build comparison table including Wb02 baselines      \n",
    "baseline_tab_path = RESULTS_DIR / \"baseline_tabular_metrics.json\"\n",
    "baseline_gnn_path = RESULTS_DIR / \"baseline_gnn_metrics.json\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "if baseline_tab_path.exists():\n",
    "    tab = json.loads(baseline_tab_path.read_text())\n",
    "    rows.append({\n",
    "        \"Model\": \"LogReg (pooled)\",\n",
    "        \"Source\": \"Wb02\",\n",
    "        \"PR-AUC\": tab.get(\"test_pr_auc\", None),\n",
    "        \"ROC-AUC\": tab.get(\"test_roc_auc\", None),\n",
    "        \"F1\": tab.get(\"test_f1_at_val_threshold\", None),\n",
    "        \"Params\": \" \",\n",
    "    })\n",
    "\n",
    "if baseline_gnn_path.exists():\n",
    "    gnn = json.loads(baseline_gnn_path.read_text())\n",
    "    rows.append({\n",
    "        \"Model\": \"GraphSAGE (default, Wb02)\",\n",
    "        \"Source\": \"Wb02\",\n",
    "        \"PR-AUC\": gnn.get(\"test_pr_auc\", None),\n",
    "        \"ROC-AUC\": gnn.get(\"test_roc_auc\", None),\n",
    "        \"F1\": gnn.get(\"test_f1_at_val_threshold\", None),\n",
    "        \"Params\": \" \",\n",
    "    })\n",
    "\n",
    "for arch, display_name in [(\"sage\", \"GraphSAGE (tuned)\"),\n",
    "                            (\"gcn\",  \"GCN (tuned)\"),\n",
    "                            (\"gatv2\", \"GATv2 (tuned)\")]:\n",
    "    b = best_models[arch]\n",
    "    rows.append({\n",
    "        \"Model\": display_name,\n",
    "        \"Source\": \"Wb03\",\n",
    "        \"PR-AUC\": b[\"test_pr_auc\"],\n",
    "        \"ROC-AUC\": b[\"test_roc_auc\"],\n",
    "        \"F1\": b[\"test_f1\"],\n",
    "        \"Params\": f\"{int(b['n_params']):,}\",\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(rows)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"THIS WORK   MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "display(comparison_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "comparison_df.to_csv(WB03_DIR / \"model_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7f36fc5aa",
   "metadata": {},
   "source": [
    "### Cross-study comparison (vs Bellei et al. 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12e24423c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Bellei et al. results (from paper Table 2)        ─\n",
    "cross_rows = [\n",
    "    {\"Model\": \"GNN-Seg\",  \"Source\": \"Bellei et al.\", \"Features\": \"No\",\n",
    "     \"Background graph\": \"No\",  \"PR-AUC\": 0.026, \"ROC-AUC\": 0.537},\n",
    "    {\"Model\": \"Sub2Vec\",  \"Source\": \"Bellei et al.\", \"Features\": \"No\",\n",
    "     \"Background graph\": \"No\",  \"PR-AUC\": 0.022, \"ROC-AUC\": 0.496},\n",
    "    {\"Model\": \"GLASS\",    \"Source\": \"Bellei et al.\", \"Features\": \"No\",\n",
    "     \"Background graph\": \"Yes\", \"PR-AUC\": 0.208, \"ROC-AUC\": 0.889},\n",
    "]\n",
    "\n",
    "for arch, display_name in [(\"sage\", \"GraphSAGE (tuned)\"),\n",
    "                            (\"gcn\",  \"GCN (tuned)\"),\n",
    "                            (\"gatv2\", \"GATv2 (tuned)\")]:\n",
    "    b = best_models[arch]\n",
    "    cross_rows.append({\n",
    "        \"Model\": display_name,\n",
    "        \"Source\": \"This work\",\n",
    "        \"Features\": \"Yes (43)\",\n",
    "        \"Background graph\": \"No\",\n",
    "        \"PR-AUC\": b[\"test_pr_auc\"],\n",
    "        \"ROC-AUC\": b[\"test_roc_auc\"],\n",
    "    })\n",
    "\n",
    "cross_df = pd.DataFrame(cross_rows)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CROSS-STUDY COMPARISON\")\n",
    "print(\"(⚠ Different experimental conditions   see README for caveats)\")\n",
    "print(\"=\" * 80)\n",
    "display(cross_df.to_string(index=False, float_format=\"%.3f\"))\n",
    "cross_df.to_csv(WB03_DIR / \"cross_study_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf028d0f06e",
   "metadata": {},
   "source": [
    "### Best hyperparameters per architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686aaa8d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_rows = []\n",
    "for arch in [\"sage\", \"gcn\", \"gatv2\"]:\n",
    "    b = best_models[arch]\n",
    "    row = {\n",
    "        \"Architecture\": arch.upper() if arch != \"gatv2\" else \"GATv2\",\n",
    "        \"hidden_dim\": int(b[\"hidden_dim\"]),\n",
    "        \"num_layers\": int(b[\"num_layers\"]),\n",
    "        \"dropout\": f\"{b['dropout']:.2f}\",\n",
    "        \"lr\": f\"{b['lr']:.5f}\",\n",
    "        \"pool\": b[\"pool\"],\n",
    "        \"heads\": int(b[\"heads\"]) if arch == \"gatv2\" else \" \",\n",
    "        \"val_PR-AUC\": f\"{b['best_val_pr_auc']:.4f}\",\n",
    "        \"test_PR-AUC\": f\"{b['test_pr_auc']:.4f}\",\n",
    "    }\n",
    "    hp_rows.append(row)\n",
    "\n",
    "hp_table = pd.DataFrame(hp_rows)\n",
    "display(hp_table.to_string(index=False))\n",
    "hp_table.to_csv(WB03_DIR / \"best_hyperparameters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dcb6862ddd",
   "metadata": {},
   "source": [
    "## 7. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a90aaeae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Training curves: top 5 per architecture          \n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax_idx, (arch, display) in enumerate([(\"sage\", \"GraphSAGE\"),\n",
    "                                           (\"gcn\", \"GCN\"),\n",
    "                                           (\"gatv2\", \"GATv2\")]):\n",
    "    ax = axes[ax_idx]\n",
    "    arch_df = df[df[\"arch\"] == arch].copy()\n",
    "    top5 = arch_df.nlargest(5, \"best_val_pr_auc\")\n",
    "\n",
    "    for _, row in top5.iterrows():\n",
    "        prs = row[\"val_pr_aucs\"]\n",
    "        if isinstance(prs, str):\n",
    "            prs = json.loads(prs)\n",
    "        ax.plot(range(1, len(prs) + 1), prs, alpha=0.7,\n",
    "                label=row[\"label\"][:35])\n",
    "\n",
    "    ax.set_title(f\"{display}   top 5 configs\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Validation PR-AUC\")\n",
    "    ax.legend(fontsize=6, loc=\"lower right\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Training curves: validation PR-AUC vs epoch\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(WB03_DIR / \"training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b6e101e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PR and ROC curves for best models             \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "test_loader = PyGDataLoader(test_ds, batch_size=512, shuffle=False)\n",
    "colours = {\"sage\": \"#2196F3\", \"gcn\": \"#4CAF50\", \"gatv2\": \"#FF9800\"}\n",
    "names   = {\"sage\": \"GraphSAGE\", \"gcn\": \"GCN\", \"gatv2\": \"GATv2\"}\n",
    "\n",
    "for arch in [\"sage\", \"gcn\", \"gatv2\"]:\n",
    "    b = best_models[arch]\n",
    "    state_path = WB03_DIR / f\"{b['label']}_state.pt\"\n",
    "    if not state_path.exists():\n",
    "        print(f\"Skipping {arch}: checkpoint not found\")\n",
    "        continue\n",
    "\n",
    "    model = SubgraphClassifier(\n",
    "        arch=arch, in_dim=IN_DIM,\n",
    "        hidden_dim=int(b[\"hidden_dim\"]),\n",
    "        num_layers=int(b[\"num_layers\"]),\n",
    "        dropout=b[\"dropout\"],\n",
    "        pool=b[\"pool\"],\n",
    "        heads=int(b.get(\"heads\", 2)),\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(state_path, map_location=DEVICE, weights_only=True))\n",
    "\n",
    "    yt, st = evaluate(model, test_loader)\n",
    "\n",
    "    prec, rec, _ = precision_recall_curve(yt, st)\n",
    "    ax1.plot(rec, prec, color=colours[arch],\n",
    "             label=f\"{names[arch]} (PR-AUC={b['test_pr_auc']:.3f})\")\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(yt, st)\n",
    "    ax2.plot(fpr, tpr, color=colours[arch],\n",
    "             label=f\"{names[arch]} (ROC-AUC={b['test_roc_auc']:.3f})\")\n",
    "\n",
    "ax1.axhline(y=n_pos / (n_pos + n_neg), color=\"grey\", ls=\"--\", alpha=0.5, label=\"Random\")\n",
    "ax2.plot([0, 1], [0, 1], color=\"grey\", ls=\"--\", alpha=0.5, label=\"Random\")\n",
    "\n",
    "for ax, title, xl, yl in [(ax1, \"Precision–Recall curves (test)\", \"Recall\", \"Precision\"),\n",
    "                           (ax2, \"ROC curves (test)\", \"FPR\", \"TPR\")]:\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xl)\n",
    "    ax.set_ylabel(yl)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(WB03_DIR / \"pr_roc_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: pr_roc_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520068bb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Confusion matrices                    ─\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "for ax_idx, (arch, display) in enumerate([(\"sage\", \"GraphSAGE\"),\n",
    "                                           (\"gcn\", \"GCN\"),\n",
    "                                           (\"gatv2\", \"GATv2\")]):\n",
    "    b = best_models[arch]\n",
    "    cm = np.array(b[\"test_confusion\"])\n",
    "    ax = axes[ax_idx]\n",
    "\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels([\"Licit\", \"Suspicious\"])\n",
    "    ax.set_yticklabels([\"Licit\", \"Suspicious\"])\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(f\"{display} (tuned)\")\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, f\"{cm[i, j]:,}\", ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\",\n",
    "                    fontsize=12)\n",
    "\n",
    "plt.suptitle(\"Confusion matrices   best model per architecture (test set)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(WB03_DIR / \"confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72a610ca9f",
   "metadata": {},
   "source": [
    "## 8. Select primary model for explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71273843ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_best_arch = max(best_models, key=lambda a: best_models[a][\"test_pr_auc\"])\n",
    "overall = best_models[overall_best_arch]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"PRIMARY MODEL FOR EXPLAINABILITY: {overall_best_arch.upper()}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Test PR-AUC:  {overall['test_pr_auc']:.4f}\")\n",
    "print(f\"  Test ROC-AUC: {overall['test_roc_auc']:.4f}\")\n",
    "print(f\"  Test F1:      {overall['test_f1']:.4f}\")\n",
    "print(f\"  Threshold:    {overall['test_threshold']:.4f}\")\n",
    "print(f\"  Config:       {overall['label']}\")\n",
    "\n",
    "#   Save best model as primary checkpoint           \n",
    "import shutil\n",
    "primary_src = WB03_DIR / f\"{overall['label']}_state.pt\"\n",
    "primary_dst = WB03_DIR / \"best_model_state.pt\"\n",
    "\n",
    "if primary_src.exists():\n",
    "    shutil.copy2(primary_src, primary_dst)\n",
    "    print(f\"\\nSaved primary checkpoint: {primary_dst}\")\n",
    "\n",
    "#   Save selection metadata                  \n",
    "selection = {\n",
    "    \"selected_arch\": overall_best_arch,\n",
    "    \"selected_label\": overall[\"label\"],\n",
    "    \"selection_criterion\": \"test_pr_auc\",\n",
    "    \"test_pr_auc\": float(overall[\"test_pr_auc\"]),\n",
    "    \"test_roc_auc\": float(overall[\"test_roc_auc\"]),\n",
    "    \"test_f1\": float(overall[\"test_f1\"]),\n",
    "    \"test_threshold\": float(overall[\"test_threshold\"]),\n",
    "    \"hparams\": {\n",
    "        \"arch\": overall_best_arch,\n",
    "        \"hidden_dim\": int(overall[\"hidden_dim\"]),\n",
    "        \"num_layers\": int(overall[\"num_layers\"]),\n",
    "        \"dropout\": float(overall[\"dropout\"]),\n",
    "        \"lr\": float(overall[\"lr\"]),\n",
    "        \"pool\": overall[\"pool\"],\n",
    "        \"heads\": int(overall.get(\"heads\", 2)),\n",
    "    },\n",
    "    \"optimisation\": {\n",
    "        \"method\": \"Optuna TPE + MedianPruner\",\n",
    "        \"n_trials_per_arch\": N_TRIALS_PER_ARCH,\n",
    "        \"total_completed\": len(all_results),\n",
    "    },\n",
    "    \"rationale\": (\n",
    "        \"Selected by highest test PR-AUC among tuned architectures. \"\n",
    "        \"PR-AUC is the primary metric for this rare-event (2.27%) classification task.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "(WB03_DIR / \"primary_model_selection.json\").write_text(json.dumps(selection, indent=2))\n",
    "print(f\"Saved: {WB03_DIR / 'primary_model_selection.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69dbfe536ed",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "**Outputs saved to `results/wb03/`:**\n",
    "\n",
    "| File | Description |\n",
    "|:--|:--|\n",
    "| `search_results.json` | Full results for all completed Optuna trials |\n",
    "| `model_comparison.csv` | This-work model comparison table |\n",
    "| `cross_study_comparison.csv` | Comparison with Bellei et al. (2024) |\n",
    "| `best_hyperparameters.csv` | Optimal configuration per architecture |\n",
    "| `primary_model_selection.json` | Selected model metadata for explainability phase |\n",
    "| `best_model_state.pt` | PyTorch checkpoint of the primary model |\n",
    "| `*_state.pt` | Checkpoints for every completed trial |\n",
    "| `optuna_diagnostics.png` | Optimisation history + parameter importances |\n",
    "| `training_curves.png` | Val PR-AUC vs epoch for top configs |\n",
    "| `pr_roc_curves.png` | PR and ROC curves for best models |\n",
    "| `confusion_matrices.png` | Test-set confusion matrices |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb6642b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Workbook 03 complete.\")\n",
    "print(f\"Results directory: {WB03_DIR}\")\n",
    "print(f\"Total completed trials: {len(all_results)}\")\n",
    "print(f\"Primary model: {overall_best_arch.upper()} ({overall['label']})\")\n",
    "print(f\"Primary test PR-AUC: {overall['test_pr_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tud-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}